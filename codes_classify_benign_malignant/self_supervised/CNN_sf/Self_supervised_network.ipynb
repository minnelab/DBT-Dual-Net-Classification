{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class CustomContrastiveDataset(Dataset):\n",
    "    def __init__(self, data_dir,base_transform=None,transform1=None, transform2=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.base_transform=base_transform\n",
    "        self.transform_pos = transform1\n",
    "        self.transform_neg = transform2\n",
    "        self.image_paths = self._load_image_paths(data_dir)\n",
    "        self.patient_data = self._group_images_by_patient()\n",
    "\n",
    "    def _load_image_paths(self, data_dir):\n",
    "        return [os.path.join(data_dir, img_name) for img_name in os.listdir(data_dir) if img_name.endswith('.png')]\n",
    "    \n",
    "    def _group_images_by_patient(self):\n",
    "        patient_dict = {}\n",
    "        for img_path in self.image_paths:\n",
    "            patient_id = self.get_patient_id(img_path)\n",
    "            if patient_id not in patient_dict:\n",
    "                patient_dict[patient_id] = []\n",
    "            patient_dict[patient_id].append(img_path)\n",
    "        return patient_dict\n",
    "    \n",
    "    def get_patient_id(self, img_name):\n",
    "        return img_name.split('_')[0]\n",
    "    \n",
    "    def get_side_view(self, img_name):\n",
    "        if 'r' in img_name:\n",
    "            return 'r' \n",
    "        elif 'l' in img_name:\n",
    "            return 'l'\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        image_name = os.path.basename(img_path)\n",
    "        patient_id = self.get_patient_id(image_name)\n",
    "        side_view = self.get_side_view(image_name)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            positive_img = img\n",
    "            if self.transform_pos:\n",
    "                positive_img = self.transform_pos(img)\n",
    "                img = self.base_transform(img) \n",
    "            return img, positive_img, 1\n",
    "        else:\n",
    "            other_patients = [pid for pid in self.patient_data if pid != patient_id]\n",
    "            if other_patients:\n",
    "                negative_patient_id = random.choice(other_patients)\n",
    "                negative_img_path = random.choice(self.patient_data[negative_patient_id])\n",
    "            else:\n",
    "                all_images = self.patient_data[patient_id]\n",
    "                negative_img_path = random.choice([img_path for img_path in all_images if self.get_side_view(img_path) != side_view])\n",
    "            negative_img = Image.open(negative_img_path).convert(\"L\")\n",
    "            if self.transform_neg:\n",
    "                negative_img = self.transform_neg(negative_img)\n",
    "                img = self.base_transform(img) \n",
    "            return img, negative_img, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "transform1 = transforms.Compose([\n",
    "    base_transform,\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15), # 你可以根据需要调整旋转角度\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    base_transform,\n",
    "    transforms.RandomRotation(degrees=5),  # 你可以根据需要调整旋转角度\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomContrastiveDataset(data_dir=r\"F:\\Dataset\\Train_tumor\\train_phase2\\rgb_all_png\\train_extend_DBT_slice_rgb_patch3\", base_transform=base_transform,transform1=transform1, transform2=transform2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveNet, self).__init__()\n",
    "        # 特征提取器\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 输入通道为1（灰度图像）\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # 全局平均池化\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128)  # 输出特征维度为128\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 提取特征\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.fc(x)\n",
    "        # L2归一化\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, feature1, feature2, label):\n",
    "        distance = F.pairwise_distance(feature1, feature2)\n",
    "        loss = torch.mean((1 - label) * torch.pow(distance, 2) +  # 正样本对\n",
    "                          label * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2))  # 负样本对\n",
    "        return loss\n",
    "\n",
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(InfoNCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, feature1, feature2,label):\n",
    "        similarity_matrix = torch.matmul(feature1, feature2.T) / self.temperature\n",
    "        pos_similarity = torch.diag(similarity_matrix)\n",
    "        neg_similarity = torch.logsumexp(similarity_matrix, dim=1) - pos_similarity\n",
    "        loss = -torch.mean((1 - label) * pos_similarity - label * neg_similarity)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.4663\n",
      "Saved best model with loss: 0.4663\n",
      "Epoch [2/100], Loss: 0.4363\n",
      "Saved best model with loss: 0.4363\n",
      "Epoch [3/100], Loss: 0.4344\n",
      "Saved best model with loss: 0.4344\n",
      "Epoch [4/100], Loss: 0.3069\n",
      "Saved best model with loss: 0.3069\n",
      "Epoch [5/100], Loss: 0.2456\n",
      "Saved best model with loss: 0.2456\n",
      "Epoch [6/100], Loss: 0.2477\n",
      "Epoch [7/100], Loss: 0.1894\n",
      "Saved best model with loss: 0.1894\n",
      "Epoch [8/100], Loss: 0.1583\n",
      "Saved best model with loss: 0.1583\n",
      "Epoch [9/100], Loss: 0.1888\n",
      "Epoch [10/100], Loss: 0.1783\n",
      "Epoch [11/100], Loss: 0.1649\n",
      "Epoch [12/100], Loss: 0.1777\n",
      "Epoch [13/100], Loss: 0.1974\n",
      "Epoch [14/100], Loss: 0.1908\n",
      "Epoch [15/100], Loss: 0.1479\n",
      "Saved best model with loss: 0.1479\n",
      "Epoch [16/100], Loss: 0.1584\n",
      "Epoch [17/100], Loss: 0.1817\n",
      "Epoch [18/100], Loss: 0.1624\n",
      "Epoch [19/100], Loss: 0.1513\n",
      "Epoch [20/100], Loss: 0.1739\n",
      "Epoch [21/100], Loss: 0.1672\n",
      "Epoch [22/100], Loss: 0.1441\n",
      "Saved best model with loss: 0.1441\n",
      "Epoch [23/100], Loss: 0.1400\n",
      "Saved best model with loss: 0.1400\n",
      "Epoch [24/100], Loss: 0.1386\n",
      "Saved best model with loss: 0.1386\n",
      "Epoch [25/100], Loss: 0.1788\n",
      "Epoch [26/100], Loss: 0.1572\n",
      "Epoch [27/100], Loss: 0.1325\n",
      "Saved best model with loss: 0.1325\n",
      "Epoch [28/100], Loss: 0.1655\n",
      "Epoch [29/100], Loss: 0.1369\n",
      "Epoch [30/100], Loss: 0.1344\n",
      "Epoch [31/100], Loss: 0.1333\n",
      "Epoch [32/100], Loss: 0.1427\n",
      "Epoch [33/100], Loss: 0.1232\n",
      "Saved best model with loss: 0.1232\n",
      "Epoch [34/100], Loss: 0.1257\n",
      "Epoch [35/100], Loss: 0.1757\n",
      "Epoch [36/100], Loss: 0.1510\n",
      "Epoch [37/100], Loss: 0.1882\n",
      "Epoch [38/100], Loss: 0.1932\n",
      "Epoch [39/100], Loss: 0.1626\n",
      "Epoch [40/100], Loss: 0.1473\n",
      "Epoch [41/100], Loss: 0.1792\n",
      "Epoch [42/100], Loss: 0.1502\n",
      "Epoch [43/100], Loss: 0.1298\n",
      "Epoch [44/100], Loss: 0.1400\n",
      "Epoch [45/100], Loss: 0.1574\n",
      "Epoch [46/100], Loss: 0.1220\n",
      "Saved best model with loss: 0.1220\n",
      "Epoch [47/100], Loss: 0.1671\n",
      "Epoch [48/100], Loss: 0.1378\n",
      "Epoch [49/100], Loss: 0.1610\n",
      "Epoch [50/100], Loss: 0.1377\n",
      "Epoch [51/100], Loss: 0.1241\n",
      "Epoch [52/100], Loss: 0.1599\n",
      "Epoch [53/100], Loss: 0.1484\n",
      "Epoch [54/100], Loss: 0.1370\n",
      "Epoch [55/100], Loss: 0.1492\n",
      "Epoch [56/100], Loss: 0.1528\n",
      "Epoch [57/100], Loss: 0.1606\n",
      "Epoch [58/100], Loss: 0.1345\n",
      "Epoch [59/100], Loss: 0.1334\n",
      "Epoch [60/100], Loss: 0.1263\n",
      "Epoch [61/100], Loss: 0.1352\n",
      "Epoch [62/100], Loss: 0.1559\n",
      "Epoch [63/100], Loss: 0.0919\n",
      "Saved best model with loss: 0.0919\n",
      "Epoch [64/100], Loss: 0.1443\n",
      "Epoch [65/100], Loss: 0.1711\n",
      "Epoch [66/100], Loss: 0.1301\n",
      "Epoch [67/100], Loss: 0.1312\n",
      "Epoch [68/100], Loss: 0.1148\n",
      "Epoch [69/100], Loss: 0.1363\n",
      "Epoch [70/100], Loss: 0.1214\n",
      "Epoch [71/100], Loss: 0.1149\n",
      "Epoch [72/100], Loss: 0.1398\n",
      "Epoch [73/100], Loss: 0.1586\n",
      "Epoch [74/100], Loss: 0.1369\n",
      "Epoch [75/100], Loss: 0.1339\n",
      "Epoch [76/100], Loss: 0.1376\n",
      "Epoch [77/100], Loss: 0.1619\n",
      "Epoch [78/100], Loss: 0.1596\n",
      "Epoch [79/100], Loss: 0.1443\n",
      "Epoch [80/100], Loss: 0.1380\n",
      "Epoch [81/100], Loss: 0.1388\n",
      "Epoch [82/100], Loss: 0.1234\n",
      "Epoch [83/100], Loss: 0.1497\n",
      "Epoch [84/100], Loss: 0.1168\n",
      "Epoch [85/100], Loss: 0.1153\n",
      "Epoch [86/100], Loss: 0.1295\n",
      "Epoch [87/100], Loss: 0.1221\n",
      "Epoch [88/100], Loss: 0.1241\n",
      "Epoch [89/100], Loss: 0.1041\n",
      "Epoch [90/100], Loss: 0.1230\n",
      "Epoch [91/100], Loss: 0.1575\n",
      "Epoch [92/100], Loss: 0.1648\n",
      "Epoch [93/100], Loss: 0.1322\n",
      "Epoch [94/100], Loss: 0.1265\n",
      "Epoch [95/100], Loss: 0.1363\n",
      "Epoch [96/100], Loss: 0.1317\n",
      "Epoch [97/100], Loss: 0.1403\n",
      "Epoch [98/100], Loss: 0.1272\n",
      "Epoch [99/100], Loss: 0.1196\n",
      "Epoch [100/100], Loss: 0.1331\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = ContrastiveNet()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=150):\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            img1, img2, label = batch\n",
    "            feature1 = model(img1)\n",
    "            feature2 = model(img2)\n",
    "            loss = criterion(feature1, feature2,label)  # 如果使用 ContrastiveLoss，需要传入 label\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            best_model_state = model.state_dict()  # 保存最佳模型状态\n",
    "        else:\n",
    "            best_model_state = None\n",
    "\n",
    "        \n",
    "        if best_model_state is not None:\n",
    "            torch.save(best_model_state, \"best_contrastive_model.pth\")\n",
    "            print(f\"Saved best model with loss: {best_loss:.4f}\")\n",
    "# 开始训练\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset_path, json_path, transform=None, augment_transform=None, n=2):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.augment_transform = augment_transform\n",
    "        self.n = n\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.labels = json.load(f)\n",
    "\n",
    "        self.image_files = [f for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files) * self.n\n",
    "    \n",
    "    def _extract_prefix(self, filename):\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            prefix = '_'.join(parts[:3])\n",
    "            view_char = parts[2]\n",
    "            return prefix,view_char\n",
    "        return filename  # 如果不足三个 '_'，返回原文件名\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx % len(self.image_files)\n",
    "\n",
    "        img_name = self.image_files[original_idx]\n",
    "\n",
    "        img_path = os.path.join(self.dataset_path, img_name)\n",
    "\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # 读取灰度图像\n",
    "\n",
    "        img_prefix,view_char = self._extract_prefix(img_name)\n",
    "        if view_char.lower().startswith('r'):\n",
    "            image = cv2.flip(image, 1)  # 水平翻转图像\n",
    "\n",
    "        normalized_image = image.astype(np.float32) / 255.0\n",
    "        normalized_image = (normalized_image * 255).astype(np.uint8)    \n",
    "        rgb_image = cv2.applyColorMap(normalized_image, cv2.COLORMAP_JET)\n",
    "\n",
    "        rgb_image = Image.fromarray(cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        label = -1  # 默认标签\n",
    "        for key in self.labels:\n",
    "            key_prefix,_ = self._extract_prefix(key)\n",
    "            if key_prefix == img_prefix:\n",
    "                label = self.labels[key]\n",
    "                break\n",
    "        if idx >= len(self.image_files) and self.augment_transform:\n",
    "            # 对数据增强的样本应用增强变换\n",
    "            rgb_image = self.augment_transform(rgb_image)\n",
    "        elif self.transform:\n",
    "            # 对原始样本应用默认变换\n",
    "            rgb_image = self.transform(rgb_image)\n",
    "        single_channel_image = rgb_image[1].unsqueeze(0)\n",
    "        return single_channel_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationNet(nn.Module):\n",
    "    def __init__(self, feature_extractor, num_classes=1, hidden_dim=64):\n",
    "        super(BinaryClassificationNet, self).__init__()\n",
    "        self.feature_extractor = feature_extractor  # 对比学习的特征提取器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, hidden_dim),  # 假设特征维度是128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, num_classes)  # 二分类任务\n",
    "        )\n",
    "        # 冻结特征提取器的参数\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        logits = self.classifier(features)\n",
    "        return logits  # 使用BCEWithLogitsLoss时不需要Sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYQ\\AppData\\Local\\Temp\\ipykernel_32792\\717655125.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  contrastive_model.load_state_dict(torch.load(\"best_contrastive_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "contrastive_model = ContrastiveNet()\n",
    "contrastive_model.load_state_dict(torch.load(\"best_contrastive_model.pth\"))\n",
    "feature_extractor = contrastive_model.feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = BinaryClassificationNet(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(binary_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"F:\\Dataset\\Test\\test_phase2\\rgb_all_png\\test_extend_DBT_slice_rgb_patch3\"\n",
    "json_path = r\"F:\\Dataset\\Test\\results_test.json\"\n",
    "\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图片大小\n",
    "    transforms.ToTensor(),          # 转换为Tensor\n",
    "])\n",
    "\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),            # 调整图片大小\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "    transforms.RandomRotation(10),           # 随机旋转\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 随机调整亮度和对比度\n",
    "    transforms.ToTensor(),                   # 转换为Tensor\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    json_path=json_path,\n",
    "    transform=default_transform,\n",
    "    augment_transform=augment_transform,\n",
    "    n=2\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "val_dataset  = r\"F:\\Dataset\\Val\\val_phase2\\rgb_all_png\\val_extend_DBT_slice_rgb_patch3\"\n",
    "val_json = r\"F:\\Dataset\\Val\\results_val.json\"\n",
    "\n",
    "val_dataset =CustomDataset(\n",
    "    dataset_path=val_dataset,\n",
    "    json_path=val_json,\n",
    "    transform=default_transform,\n",
    "    augment_transform=augment_transform,\n",
    "    n=2\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassificationNet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, matthews_corrcoef,\n",
    "                             cohen_kappa_score, confusion_matrix, classification_report)\n",
    "import numpy as np\n",
    "\n",
    "def train_model(train_dataloader, val_dataloader, model, criterion, optimizer, num_epochs=10):\n",
    "    best_auc = 0.0  # 用于保存最高的 AUC 值\n",
    "    log_file = \"training_log.txt\"  # 日志文件路径\n",
    "\n",
    "    # 打开日志文件\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Epoch\\tTrain Loss\\tTrain Accuracy\\tTrain AUC\\tTrain Precision\\tTrain Sensitivity\\tTrain Specificity\\tTrain f1\\tVal Accuracy\\tVal AUC\\tVal Precision\\tVal Sensitivity\\tVal Specificity\\tVal f1\\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for images, labels in train_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_preds.extend(outputs.squeeze().detach().cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "        train_accuracy = accuracy_score(train_labels, (np.array(train_preds) > 0.5).astype(int))\n",
    "        train_auc = roc_auc_score(train_labels, train_preds)\n",
    "        train_precision = precision_score(train_labels, (np.array(train_preds) > 0.5).astype(int))\n",
    "        train_sensitivity = recall_score(train_labels, (np.array(train_preds) > 0.5).astype(int))\n",
    "        train_specificity = recall_score(train_labels, (np.array(train_preds) > 0.5).astype(int), pos_label=0)\n",
    "        train_f1score = f1_score(train_labels, (np.array(train_preds) > 0.5).astype(int))\n",
    "\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_dataloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.float()\n",
    "                outputs = model(images)\n",
    "                val_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, (np.array(val_preds) > 0.5).astype(int))\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "        val_precision = precision_score(val_labels, (np.array(val_preds) > 0.5).astype(int))\n",
    "        val_sensitivity = recall_score(val_labels, (np.array(val_preds) > 0.5).astype(int))\n",
    "        val_specificity = recall_score(val_labels, (np.array(val_preds) > 0.5).astype(int), pos_label=0)\n",
    "        val_f1score = f1_score(val_labels, (np.array(val_preds) > 0.5).astype(int))\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Train AUC: {train_auc:.4f}, \"\n",
    "              f\"Train Precision: {train_precision:.4f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy:.4f}, \"\n",
    "              f\"Val AUC: {val_auc:.4f}, \"\n",
    "              f\"Val Precision: {val_precision:.4f}\")\n",
    "\n",
    "        # 保存指标到日志文件\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(f\"{epoch + 1}\\t{train_loss:.4f}\\t{train_accuracy:.4f}\\t{train_auc:.4f}\\t{train_precision:.4f}\\t{train_sensitivity:.4f}\\t{train_specificity:.4f}\\t{train_f1score:.4f}\\t\"\n",
    "                    f\"{val_accuracy:.4f}\\t{val_auc:.4f}\\t{val_precision:.4f}\\t{val_sensitivity:.4f}\\t{val_specificity:.4f}\\t{val_f1score:.4f}\\n\")\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(f\"New best model saved with AUC: {best_auc:.4f}\")\n",
    "\n",
    "model = binary_model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.6929, Train Accuracy: 0.4762, Train AUC: 0.4154, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6662, Val Precision: 0.0000\n",
      "New best model saved with AUC: 0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.6921, Train Accuracy: 0.4762, Train AUC: 0.4967, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6502, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.6920, Train Accuracy: 0.4762, Train AUC: 0.4937, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6962, Val Precision: 0.0000\n",
      "New best model saved with AUC: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.6913, Train Accuracy: 0.4762, Train AUC: 0.4954, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6857, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.6909, Train Accuracy: 0.4762, Train AUC: 0.5156, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6655, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.6907, Train Accuracy: 0.4762, Train AUC: 0.5113, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6674, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.6903, Train Accuracy: 0.4762, Train AUC: 0.5049, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6676, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.6894, Train Accuracy: 0.4762, Train AUC: 0.5283, Train Precision: 0.0000, Val Accuracy: 0.5072, Val AUC: 0.6513, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.6893, Train Accuracy: 0.4802, Train AUC: 0.5402, Train Precision: 1.0000, Val Accuracy: 0.5072, Val AUC: 0.6595, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.6887, Train Accuracy: 0.4921, Train AUC: 0.5278, Train Precision: 1.0000, Val Accuracy: 0.5072, Val AUC: 0.6601, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.6891, Train Accuracy: 0.4921, Train AUC: 0.5128, Train Precision: 1.0000, Val Accuracy: 0.5072, Val AUC: 0.6765, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.6884, Train Accuracy: 0.4881, Train AUC: 0.5215, Train Precision: 0.8000, Val Accuracy: 0.5072, Val AUC: 0.6571, Val Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\learningDL\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.6866, Train Accuracy: 0.4881, Train AUC: 0.5514, Train Precision: 0.8000, Val Accuracy: 0.5072, Val AUC: 0.6620, Val Precision: 0.0000\n",
      "Epoch [14/50], Train Loss: 0.6871, Train Accuracy: 0.4881, Train AUC: 0.5302, Train Precision: 0.7143, Val Accuracy: 0.5217, Val AUC: 0.6559, Val Precision: 1.0000\n",
      "Epoch [15/50], Train Loss: 0.6879, Train Accuracy: 0.4881, Train AUC: 0.5450, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6700, Val Precision: 1.0000\n",
      "Epoch [16/50], Train Loss: 0.6859, Train Accuracy: 0.4841, Train AUC: 0.5665, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6622, Val Precision: 1.0000\n",
      "Epoch [17/50], Train Loss: 0.6854, Train Accuracy: 0.4960, Train AUC: 0.5588, Train Precision: 0.7778, Val Accuracy: 0.5217, Val AUC: 0.6546, Val Precision: 1.0000\n",
      "Epoch [18/50], Train Loss: 0.6850, Train Accuracy: 0.4921, Train AUC: 0.5683, Train Precision: 0.7500, Val Accuracy: 0.5217, Val AUC: 0.6712, Val Precision: 1.0000\n",
      "Epoch [19/50], Train Loss: 0.6858, Train Accuracy: 0.4921, Train AUC: 0.5593, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6805, Val Precision: 1.0000\n",
      "Epoch [20/50], Train Loss: 0.6855, Train Accuracy: 0.4960, Train AUC: 0.5611, Train Precision: 0.7778, Val Accuracy: 0.5217, Val AUC: 0.6744, Val Precision: 1.0000\n",
      "Epoch [21/50], Train Loss: 0.6843, Train Accuracy: 0.4960, Train AUC: 0.5754, Train Precision: 0.7273, Val Accuracy: 0.5217, Val AUC: 0.6836, Val Precision: 1.0000\n",
      "Epoch [22/50], Train Loss: 0.6832, Train Accuracy: 0.4960, Train AUC: 0.5866, Train Precision: 0.7273, Val Accuracy: 0.5217, Val AUC: 0.6702, Val Precision: 1.0000\n",
      "Epoch [23/50], Train Loss: 0.6837, Train Accuracy: 0.4881, Train AUC: 0.5913, Train Precision: 0.8000, Val Accuracy: 0.5217, Val AUC: 0.6798, Val Precision: 1.0000\n",
      "Epoch [24/50], Train Loss: 0.6837, Train Accuracy: 0.4921, Train AUC: 0.5682, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6775, Val Precision: 1.0000\n",
      "Epoch [25/50], Train Loss: 0.6830, Train Accuracy: 0.4960, Train AUC: 0.5866, Train Precision: 0.7273, Val Accuracy: 0.5362, Val AUC: 0.6815, Val Precision: 1.0000\n",
      "Epoch [26/50], Train Loss: 0.6819, Train Accuracy: 0.4960, Train AUC: 0.5888, Train Precision: 0.7273, Val Accuracy: 0.5217, Val AUC: 0.6769, Val Precision: 1.0000\n",
      "Epoch [27/50], Train Loss: 0.6805, Train Accuracy: 0.4960, Train AUC: 0.6030, Train Precision: 0.7273, Val Accuracy: 0.5362, Val AUC: 0.6737, Val Precision: 1.0000\n",
      "Epoch [28/50], Train Loss: 0.6827, Train Accuracy: 0.4841, Train AUC: 0.5790, Train Precision: 0.5714, Val Accuracy: 0.5217, Val AUC: 0.6628, Val Precision: 1.0000\n",
      "Epoch [29/50], Train Loss: 0.6805, Train Accuracy: 0.4921, Train AUC: 0.6037, Train Precision: 0.6000, Val Accuracy: 0.5217, Val AUC: 0.6838, Val Precision: 1.0000\n",
      "Epoch [30/50], Train Loss: 0.6803, Train Accuracy: 0.5000, Train AUC: 0.6073, Train Precision: 0.8000, Val Accuracy: 0.5217, Val AUC: 0.6739, Val Precision: 1.0000\n",
      "Epoch [31/50], Train Loss: 0.6801, Train Accuracy: 0.5000, Train AUC: 0.6011, Train Precision: 0.8000, Val Accuracy: 0.5217, Val AUC: 0.6721, Val Precision: 1.0000\n",
      "Epoch [32/50], Train Loss: 0.6795, Train Accuracy: 0.4921, Train AUC: 0.6038, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6708, Val Precision: 1.0000\n",
      "Epoch [33/50], Train Loss: 0.6786, Train Accuracy: 0.4960, Train AUC: 0.6100, Train Precision: 0.7273, Val Accuracy: 0.5217, Val AUC: 0.6773, Val Precision: 1.0000\n",
      "Epoch [34/50], Train Loss: 0.6769, Train Accuracy: 0.5000, Train AUC: 0.6177, Train Precision: 0.7143, Val Accuracy: 0.5290, Val AUC: 0.6798, Val Precision: 1.0000\n",
      "Epoch [35/50], Train Loss: 0.6767, Train Accuracy: 0.5000, Train AUC: 0.6187, Train Precision: 0.7500, Val Accuracy: 0.5217, Val AUC: 0.6775, Val Precision: 1.0000\n",
      "Epoch [36/50], Train Loss: 0.6762, Train Accuracy: 0.4960, Train AUC: 0.6251, Train Precision: 0.7778, Val Accuracy: 0.5362, Val AUC: 0.6817, Val Precision: 1.0000\n",
      "Epoch [37/50], Train Loss: 0.6760, Train Accuracy: 0.4960, Train AUC: 0.6227, Train Precision: 0.6923, Val Accuracy: 0.5290, Val AUC: 0.6809, Val Precision: 1.0000\n",
      "Epoch [38/50], Train Loss: 0.6762, Train Accuracy: 0.5040, Train AUC: 0.6108, Train Precision: 0.7059, Val Accuracy: 0.5217, Val AUC: 0.6842, Val Precision: 1.0000\n",
      "Epoch [39/50], Train Loss: 0.6756, Train Accuracy: 0.4960, Train AUC: 0.6176, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6710, Val Precision: 1.0000\n",
      "Epoch [40/50], Train Loss: 0.6750, Train Accuracy: 0.4921, Train AUC: 0.6206, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6752, Val Precision: 1.0000\n",
      "Epoch [41/50], Train Loss: 0.6729, Train Accuracy: 0.5040, Train AUC: 0.6284, Train Precision: 0.8182, Val Accuracy: 0.5217, Val AUC: 0.6832, Val Precision: 1.0000\n",
      "Epoch [42/50], Train Loss: 0.6739, Train Accuracy: 0.5079, Train AUC: 0.6271, Train Precision: 0.7500, Val Accuracy: 0.5362, Val AUC: 0.6735, Val Precision: 1.0000\n",
      "Epoch [43/50], Train Loss: 0.6724, Train Accuracy: 0.5000, Train AUC: 0.6258, Train Precision: 0.6667, Val Accuracy: 0.5217, Val AUC: 0.6647, Val Precision: 1.0000\n",
      "Epoch [44/50], Train Loss: 0.6721, Train Accuracy: 0.4921, Train AUC: 0.6225, Train Precision: 0.6429, Val Accuracy: 0.5217, Val AUC: 0.6767, Val Precision: 1.0000\n",
      "Epoch [45/50], Train Loss: 0.6713, Train Accuracy: 0.4960, Train AUC: 0.6265, Train Precision: 0.7273, Val Accuracy: 0.5362, Val AUC: 0.6668, Val Precision: 1.0000\n",
      "Epoch [46/50], Train Loss: 0.6695, Train Accuracy: 0.5079, Train AUC: 0.6336, Train Precision: 0.8333, Val Accuracy: 0.5435, Val AUC: 0.6775, Val Precision: 1.0000\n",
      "Epoch [47/50], Train Loss: 0.6695, Train Accuracy: 0.5079, Train AUC: 0.6301, Train Precision: 0.7500, Val Accuracy: 0.5580, Val AUC: 0.6796, Val Precision: 1.0000\n",
      "Epoch [48/50], Train Loss: 0.6705, Train Accuracy: 0.5159, Train AUC: 0.6198, Train Precision: 0.6923, Val Accuracy: 0.5290, Val AUC: 0.6702, Val Precision: 1.0000\n",
      "Epoch [49/50], Train Loss: 0.6686, Train Accuracy: 0.5278, Train AUC: 0.6285, Train Precision: 0.8095, Val Accuracy: 0.5507, Val AUC: 0.6697, Val Precision: 1.0000\n",
      "Epoch [50/50], Train Loss: 0.6674, Train Accuracy: 0.5119, Train AUC: 0.6295, Train Precision: 0.7368, Val Accuracy: 0.5507, Val AUC: 0.6634, Val Precision: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_model(train_dataloader, val_dataloader, model, criterion, optimizer, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learningDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
