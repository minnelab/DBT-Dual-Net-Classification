{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import skimage.transform\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,f1_score,recall_score\n",
    "from plt_metrics import plot_roc_curve,plot_confusion_matrix,plot_f1_curve\n",
    "from plt_metrics import save_accuracy_auc_plot,save_train_val_accuracy_plot\n",
    "from plt_metrics import plot_loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NiiDataset(Dataset):\n",
    "    def __init__(self, normal_dir, tumor_dir, target_size=(10, 224, 224),transform=None):\n",
    "        self.normal_dir = normal_dir\n",
    "        self.tumor_dir = tumor_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "\n",
    "        # Gather file paths\n",
    "        self.normal_files = [os.path.join(normal_dir, f) for f in os.listdir(normal_dir) if f.endswith(\".nii.gz\")]\n",
    "        self.tumor_files = [os.path.join(tumor_dir, f) for f in os.listdir(tumor_dir) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "        # Combine and assign labels (0 for normal, 1 for tumor)\n",
    "        self.data = [(file, 0) for file in self.normal_files] + [(file, 1) for file in self.tumor_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx]\n",
    "\n",
    "        image = sitk.ReadImage(file_path)\n",
    "        image_array = sitk.GetArrayFromImage(image) \n",
    "        reshaped_array = np.transpose(image_array, (2, 1, 0))\n",
    "\n",
    "        img_array = self.resize_image(reshaped_array)\n",
    "        img_array = img_array.astype(np.float32)\n",
    "\n",
    "             # Normalize and add channel dimension\n",
    "        img_array = torch.tensor(img_array, dtype=torch.float32)\n",
    "        img_array = img_array.unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return img_array, label\n",
    "    \n",
    "    def resize_image(self, img_array):\n",
    "        depth,height, width = img_array.shape\n",
    "        target_depth, target_height, target_width = self.target_size\n",
    "            \n",
    "            # Calculate scale factors for each dimension\n",
    "        depth_scale = target_depth / depth\n",
    "        height_scale = target_height / height\n",
    "        width_scale = target_width / width\n",
    "            \n",
    "            # Use scipy.ndimage.zoom to resize the 3D image array\n",
    "\n",
    "        resized_array = skimage.transform.resize(img_array,\n",
    "                                         output_shape=(target_depth, target_height, target_width),\n",
    "                                         mode='reflect',  # 边界处理模式\n",
    "                                         anti_aliasing=True)  # 使用抗锯齿\n",
    "        \n",
    "        return resized_array\n",
    "\n",
    "    \n",
    "train_normal_dir = \"F:/Dataset/Train_normal_more_cases/manifest-1617905855234/Breast-Cancer-Screening-DBT/3d_train\"\n",
    "train_tumor_dir = \"F:/Dataset/Train_tumor/manifest-1617905855234/Breast-Cancer-Screening-DBT/3d_slices_nii_3D_10_5P\"         # Replace with your tumor folder path\n",
    "\n",
    "train_dataset = NiiDataset(train_normal_dir, train_tumor_dir, target_size=(10, 224, 224))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "val_normal_dir = \"F:/Dataset/Train_normal_more_cases/manifest-1617905855234/Breast-Cancer-Screening-DBT/3d_val\" \n",
    "val_tumor_dir = \"F:/Dataset/Val/manifest-1617905855234/Breast-Cancer-Screening-DBT/3d_slices_nii_3D_10_5P\"         # Replace with your tumor folder path\n",
    "\n",
    "val_dataset = NiiDataset(train_normal_dir, train_tumor_dir, target_size=(10, 224, 224))\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array, label = next(iter(train_dataloader))\n",
    "print(img_array.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_DenseNet import train,validate,main_training_loop,save_loss_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.resnet import ResNet3D\n",
    "from model.resnet import BasicBlock\n",
    "\n",
    "model = ResNet3D(BasicBlock, [2, 2, 2, 2], num_classes=2)\n",
    "\n",
    "metric_folder = '3D_resnet_normal_tumor'\n",
    "\n",
    "trained_model = main_training_loop(model, train_dataloader, val_dataloader, num_epochs=50, lr=0.0001, device='cuda',metric_folder = metric_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learningDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
